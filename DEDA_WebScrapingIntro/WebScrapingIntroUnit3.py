# -*- coding: utf-8 -*-
"""DEDAUnit3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g6Z6HofpF-BJYs_WCzvCMGNdD4zlk0tp

# **DEDA Unit 3:** Introduction of Web Scraping in Python

#### **Reading XML Data Online**
"""

"""
We use json module to unpack data from webpage. 
"""

import requests
import xml.dom.minidom

response = requests.get("https://www.treasury.gov/resource-center/data-chart-center/interest-rates/Datasets/daily_treas_bill_rates.xml")
content = response.content

dataDOM = xml.dom.minidom.parseString(content)
response = requests.get("https://news.google.com/news/rss/headlines/section/q/finance%20news/finance%20news?ned=us&hl=en")

"""#### **Reading JSON Data Online**"""

"""
We use json module to unpack US GOV data and receive the number of US passport applications each fiscal year from https://cadatacatalog.state.gov/dataset .
"""

import requests
import json
import pandas as pd

url = 'https://cadatacatalog.state.gov/dataset/a765ec3a-cf98-4722-a562-40c3f03d24d5/resource/a3bb04a8-dcda-4a03-ba87-e4ec63f2c4c3/download/passportapplicationbyfiscalyear.json'

response = requests.get(url)
content = json.loads(response.content)
Year = [item['Year'] for item in content]
Count = [item['Count'] for item in content]

Info = zip(Year, Count)
PassportData = pd.DataFrame(list(Info), columns=['Year', 'Count'])
print(PassportData)

"""#### **Webpage with RSS Feed**"""

"""
Retrieving the titles from the Financial Times Website (https://www.ft.com/?edition=international) 
"""
!pip install feedparser
import feedparser
news = feedparser.parse("https://www.ft.com/?edition=international&format=rss")

for index, item in enumerate(news.entries): # list all titles
    print("{0}.{1}".format(index, item["title"]))